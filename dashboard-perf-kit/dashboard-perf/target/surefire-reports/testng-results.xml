<?xml version="1.0" encoding="UTF-8"?>
<testng-results ignored="0" total="20" passed="20" failed="0" skipped="0">
  <reporter-output>
  </reporter-output>
  <suite started-at="2025-08-19T18:49:38 IST" name="Dashboard Performance Suite" finished-at="2025-08-19T19:01:41 IST" duration-ms="723280">
    <groups>
    </groups>
    <test started-at="2025-08-19T18:49:38 IST" name="Dashboard Performance" finished-at="2025-08-19T19:01:41 IST" duration-ms="723280">
      <class name="com.perfkit.DashboardPerformanceTest">
        <test-method is-config="true" signature="init()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:49:38 IST" name="init" finished-at="2025-08-19T18:49:38 IST" duration-ms="346" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- init -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:49:38 IST" name="setUp" finished-at="2025-08-19T18:49:43 IST" duration-ms="5397" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:49:43 IST" name="measureDashboardReady" finished-at="2025-08-19T18:50:26 IST" duration-ms="42392" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:50:26 IST" name="tearDown" finished-at="2025-08-19T18:50:35 IST" duration-ms="9147" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:50:35 IST" name="setUp" finished-at="2025-08-19T18:50:36 IST" duration-ms="654" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:50:36 IST" name="measureDashboardReady" finished-at="2025-08-19T18:51:01 IST" duration-ms="25484" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:51:01 IST" name="tearDown" finished-at="2025-08-19T18:51:10 IST" duration-ms="9108" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:51:10 IST" name="setUp" finished-at="2025-08-19T18:51:11 IST" duration-ms="632" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:51:11 IST" name="measureDashboardReady" finished-at="2025-08-19T18:51:39 IST" duration-ms="28020" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:51:39 IST" name="tearDown" finished-at="2025-08-19T18:51:48 IST" duration-ms="9138" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:51:48 IST" name="setUp" finished-at="2025-08-19T18:51:49 IST" duration-ms="644" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:51:49 IST" name="measureDashboardReady" finished-at="2025-08-19T18:52:14 IST" duration-ms="25531" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:52:14 IST" name="tearDown" finished-at="2025-08-19T18:52:23 IST" duration-ms="9121" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:52:23 IST" name="setUp" finished-at="2025-08-19T18:52:24 IST" duration-ms="690" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:52:24 IST" name="measureDashboardReady" finished-at="2025-08-19T18:52:49 IST" duration-ms="25520" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:52:49 IST" name="tearDown" finished-at="2025-08-19T18:52:59 IST" duration-ms="9098" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:52:59 IST" name="setUp" finished-at="2025-08-19T18:52:59 IST" duration-ms="652" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:52:59 IST" name="measureDashboardReady" finished-at="2025-08-19T18:53:25 IST" duration-ms="25945" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:53:25 IST" name="tearDown" finished-at="2025-08-19T18:53:34 IST" duration-ms="9099" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:53:34 IST" name="setUp" finished-at="2025-08-19T18:53:35 IST" duration-ms="634" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:53:35 IST" name="measureDashboardReady" finished-at="2025-08-19T18:54:02 IST" duration-ms="27076" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:54:02 IST" name="tearDown" finished-at="2025-08-19T18:54:11 IST" duration-ms="9099" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:54:11 IST" name="setUp" finished-at="2025-08-19T18:54:12 IST" duration-ms="657" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:54:12 IST" name="measureDashboardReady" finished-at="2025-08-19T18:54:36 IST" duration-ms="23970" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:54:36 IST" name="tearDown" finished-at="2025-08-19T18:54:45 IST" duration-ms="9102" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:54:45 IST" name="setUp" finished-at="2025-08-19T18:54:45 IST" duration-ms="647" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:54:45 IST" name="measureDashboardReady" finished-at="2025-08-19T18:55:11 IST" duration-ms="25204" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:55:11 IST" name="tearDown" finished-at="2025-08-19T18:55:20 IST" duration-ms="9107" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:55:20 IST" name="setUp" finished-at="2025-08-19T18:55:20 IST" duration-ms="644" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:55:20 IST" name="measureDashboardReady" finished-at="2025-08-19T18:55:48 IST" duration-ms="27151" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:55:48 IST" name="tearDown" finished-at="2025-08-19T18:55:57 IST" duration-ms="9106" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:55:57 IST" name="setUp" finished-at="2025-08-19T18:55:57 IST" duration-ms="621" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:55:57 IST" name="measureDashboardReady" finished-at="2025-08-19T18:56:26 IST" duration-ms="29223" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:56:27 IST" name="tearDown" finished-at="2025-08-19T18:56:36 IST" duration-ms="9087" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:56:36 IST" name="setUp" finished-at="2025-08-19T18:56:36 IST" duration-ms="686" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:56:36 IST" name="measureDashboardReady" finished-at="2025-08-19T18:57:02 IST" duration-ms="25543" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:57:02 IST" name="tearDown" finished-at="2025-08-19T18:57:11 IST" duration-ms="9094" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:57:11 IST" name="setUp" finished-at="2025-08-19T18:57:12 IST" duration-ms="616" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:57:12 IST" name="measureDashboardReady" finished-at="2025-08-19T18:57:38 IST" duration-ms="26364" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:57:38 IST" name="tearDown" finished-at="2025-08-19T18:57:47 IST" duration-ms="9136" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:57:47 IST" name="setUp" finished-at="2025-08-19T18:57:48 IST" duration-ms="681" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:57:48 IST" name="measureDashboardReady" finished-at="2025-08-19T18:58:13 IST" duration-ms="24817" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:58:13 IST" name="tearDown" finished-at="2025-08-19T18:58:22 IST" duration-ms="9091" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:58:22 IST" name="setUp" finished-at="2025-08-19T18:58:22 IST" duration-ms="637" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:58:22 IST" name="measureDashboardReady" finished-at="2025-08-19T18:58:48 IST" duration-ms="25406" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:58:48 IST" name="tearDown" finished-at="2025-08-19T18:58:57 IST" duration-ms="9104" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:58:57 IST" name="setUp" finished-at="2025-08-19T18:58:57 IST" duration-ms="636" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:58:57 IST" name="measureDashboardReady" finished-at="2025-08-19T18:59:19 IST" duration-ms="22027" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:59:19 IST" name="tearDown" finished-at="2025-08-19T18:59:29 IST" duration-ms="9104" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:59:29 IST" name="setUp" finished-at="2025-08-19T18:59:29 IST" duration-ms="642" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:59:29 IST" name="measureDashboardReady" finished-at="2025-08-19T18:59:52 IST" duration-ms="22770" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T18:59:52 IST" name="tearDown" finished-at="2025-08-19T19:00:01 IST" duration-ms="9101" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T19:00:01 IST" name="setUp" finished-at="2025-08-19T19:00:02 IST" duration-ms="659" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T19:00:02 IST" name="measureDashboardReady" finished-at="2025-08-19T19:00:25 IST" duration-ms="23259" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T19:00:25 IST" name="tearDown" finished-at="2025-08-19T19:00:34 IST" duration-ms="9108" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T19:00:34 IST" name="setUp" finished-at="2025-08-19T19:00:35 IST" duration-ms="650" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T19:00:35 IST" name="measureDashboardReady" finished-at="2025-08-19T19:00:58 IST" duration-ms="23258" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T19:00:58 IST" name="tearDown" finished-at="2025-08-19T19:01:07 IST" duration-ms="9107" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="setUp()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T19:01:07 IST" name="setUp" finished-at="2025-08-19T19:01:08 IST" duration-ms="702" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setUp -->
        <test-method signature="measureDashboardReady()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T19:01:08 IST" name="measureDashboardReady" finished-at="2025-08-19T19:01:31 IST" duration-ms="23467" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- measureDashboardReady -->
        <test-method is-config="true" signature="tearDown()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T19:01:31 IST" name="tearDown" finished-at="2025-08-19T19:01:40 IST" duration-ms="9103" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method is-config="true" signature="afterClass()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T19:01:40 IST" name="afterClass" finished-at="2025-08-19T19:01:41 IST" duration-ms="426" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- afterClass -->
        <test-method is-config="true" signature="generateCharts()[pri:0, instance:com.perfkit.DashboardPerformanceTest@47d90b9e]" started-at="2025-08-19T19:01:41 IST" name="generateCharts" finished-at="2025-08-19T19:01:41 IST" duration-ms="410" status="PASS">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- generateCharts -->
      </class> <!-- com.perfkit.DashboardPerformanceTest -->
    </test> <!-- Dashboard Performance -->
  </suite> <!-- Dashboard Performance Suite -->
</testng-results>
